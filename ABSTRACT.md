**Cityscapes** is a large-scale dataset that contains a diverse set of stereo video sequences recorded in street scenes from 50 different cities, with high quality pixel-level annotations of 5 000 frames in addition to a larger set of 20 000 weakly annotated frames. The dataset is thus an order of magnitude larger than similar previous attempts. Details on [annotated classes](https://www.cityscapes-dataset.com/dataset-overview/#class-definitions) and [examples of our annotations](https://www.cityscapes-dataset.com/examples/#dense-pixel-annotations) are available at this webpage.

The Cityscapes Dataset is intended for:

1. Assessing the performance of vision algorithms for major tasks of semantic urban scene understanding: pixel-level, instance-level, and panoptic semantic labeling;
2. Supporting research that aims to exploit large volumes of (weakly) annotated data, e.g. for training deep neural networks.

Within  **DatasetNinja**, the statistics for the **Fine Annotations** version was collected. Alternatively, you can download **Coarse Annotations** version with 20000 images on the dataset's [homepage](https://www.cityscapes-dataset.com/).
